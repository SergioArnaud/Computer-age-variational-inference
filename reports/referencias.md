[1] Baydin, A. G., Pearlmutter, B. A., Radul, A. A., & Siskind, J. M. (2018). Automatic Differentiation in Machine Learning: A Survey. *Journal of Machine Learning Research,* 18 , 1-43.

[2] Vehtari, A., Gelman, A., & Gabry, J. (2017). Pareto Smoothed Importance Sampling. *Department of Statistics, Columbia University, New York.*

[3] Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic Differentiation Variational Inference. *Journal of Machine Learning Research*, 18, 1-45.

[4] David M. Blei, Alp Kucukelbir & Jon D. McAuliffe (2017) Variational Inference: A Review for Statisticians, *Journal of the American Statistical Association*, 112:518, 859-877, DOI: 10.1080/01621459.2017.1285773

[5] Yao, Y., Vehtari, A., Simpsom, D., & Gelman, A. (2018) Yes, but Did It Work?: Evaluating Variational Inference. arXiv preprint arXiv:1802.02538

[6] Q. Liu, J. D. Lee, & M. I. Jordan. (2016). A kernelized Stein discrepancy for goodness-of-fit tests and
model evaluation. *ICML*.

[7] Liu, Q. & Wang, D. (2016). Stein variational gradient descent: A general purpose bayesian inference algorithm. *In Advances In Neural Information Processing Systems*, 2370â€“2378.

[8] Liu, Qiang. (2017). Stein variational gradient descent as gradient flow. arXiv preprint arXiv:1704.07520.

